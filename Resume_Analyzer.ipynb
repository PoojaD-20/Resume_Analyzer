{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNl8neXHPZ9Q1WkIwQxs3GK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"scRRmqI2agea","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748966996013,"user_tz":-330,"elapsed":4269,"user":{"displayName":"Pooja Divekar","userId":"05944496302832483529"}},"outputId":"32c2542d-d389-41f4-ccf7-fde2b3ab5a82"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}],"source":["!pip install PyPDF2"]},{"cell_type":"code","source":["!pip install pdfplumber\n","!pip install streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ie-sP3VBLpQg","executionInfo":{"status":"ok","timestamp":1748967015061,"user_tz":-330,"elapsed":19014,"user":{"displayName":"Pooja Divekar","userId":"05944496302832483529"}},"outputId":"1fd38cdf-f4a8-402d-8d72-000d44734343"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pdfplumber\n","  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pdfminer.six==20250327 (from pdfplumber)\n","  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.2)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n","Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n","Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n","Collecting streamlit\n","  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.40.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"]}]},{"cell_type":"code","source":["import sys\n","import json\n","import pdfplumber\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","import pandas as pd\n","\n","# ğŸ† Updated Skill-to-Role Mapping (Deep Industry-Level Analysis)\n","skill_to_role_mapping = {\n","    # Software Engineering\n","    'python': ['Software Engineer', 'Backend Developer', 'Data Scientist', 'ML Engineer'],\n","    'java': ['Software Engineer', 'Backend Developer'],\n","    'c++': ['Software Engineer', 'Game Developer'],\n","    'javascript': ['Software Engineer', 'Frontend Developer', 'Full Stack Developer'],\n","    'typescript': ['Frontend Developer', 'Full Stack Developer'],\n","    'react': ['Frontend Developer', 'Full Stack Developer'],\n","    'angular': ['Frontend Developer'],\n","    'vue': ['Frontend Developer'],\n","    'node': ['Backend Developer', 'Full Stack Developer'],\n","    'express': ['Backend Developer'],\n","    'django': ['Backend Developer', 'Full Stack Developer'],\n","    'flask': ['Backend Developer'],\n","    'spring': ['Backend Developer'],\n","\n","    # Data Science & AI\n","    'machine learning': ['Data Scientist', 'ML Engineer'],\n","    'deep learning': ['ML Engineer', 'AI Researcher'],\n","    'tensorflow': ['ML Engineer', 'AI Researcher'],\n","    'pytorch': ['ML Engineer', 'AI Researcher'],\n","    'nlp': ['ML Engineer', 'AI Researcher'],\n","    'computer vision': ['ML Engineer', 'AI Researcher'],\n","    'data analysis': ['Data Analyst', 'Data Scientist'],\n","    'big data': ['Data Engineer', 'Data Scientist'],\n","    'sql': ['Data Analyst', 'Data Engineer', 'Database Administrator'],\n","    'mongodb': ['Database Administrator', 'Backend Developer'],\n","    'hadoop': ['Data Engineer'],\n","\n","    # DevOps & Cloud\n","    'aws': ['Cloud Engineer', 'DevOps Engineer'],\n","    'azure': ['Cloud Engineer', 'DevOps Engineer'],\n","    'gcp': ['Cloud Engineer'],\n","    'docker': ['DevOps Engineer'],\n","    'kubernetes': ['DevOps Engineer'],\n","    'ci/cd': ['DevOps Engineer'],\n","    'terraform': ['DevOps Engineer'],\n","\n","    # Product & Design\n","    'product management': ['Product Manager'],\n","    'agile': ['Product Manager', 'Scrum Master'],\n","    'scrum': ['Scrum Master'],\n","    'figma': ['UX Designer'],\n","    'ui': ['UX Designer'],\n","    'ux': ['UX Designer'],\n","    'user research': ['UX Designer', 'Product Manager'],\n","\n","    # Cybersecurity\n","    'penetration testing': ['Cybersecurity Engineer'],\n","    'network security': ['Cybersecurity Engineer'],\n","    'ethical hacking': ['Cybersecurity Engineer'],\n","    'encryption': ['Cybersecurity Engineer'],\n","\n","    # Blockchain & Web3\n","    'solidity': ['Blockchain Developer'],\n","    'web3': ['Blockchain Developer'],\n","    'ethereum': ['Blockchain Developer'],\n","\n","    # Soft Skills (Bonus Analysis)\n","    'leadership': ['Manager', 'Team Lead'],\n","    'communication': ['Manager', 'Team Lead', 'Product Manager'],\n","    'teamwork': ['Any Role']\n","}\n","\n","# ğŸ”¹ Extract Text from Resume\n","def extract_text_from_pdf(pdf_path):\n","    try:\n","        with pdfplumber.open(pdf_path) as pdf:\n","            text = \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n","        return text.strip()\n","    except Exception as e:\n","        print(json.dumps({\"error\": f\"Error reading PDF: {str(e)}\"}))\n","        sys.exit(1)\n","\n","# ğŸ”¹ Extract Skills from Resume\n","def extract_skills(resume_text):\n","    resume_text_lower = resume_text.lower()\n","    found_skills = [skill for skill in skill_to_role_mapping if skill in resume_text_lower]\n","    return found_skills\n","\n","# ğŸ”¹ Predict Role from Extracted Skills\n","def predict_roles(skills):\n","    matched_roles = set()\n","    for skill in skills:\n","        matched_roles.update(skill_to_role_mapping.get(skill, []))\n","    return list(matched_roles) if matched_roles else [\"General Software Engineer\"]  # Default role\n","\n","# ğŸ”¹ Dummy ML Model for Role Prediction (Training)\n","data = {\n","    \"resume\": [\n","        \"Python, Machine Learning, TensorFlow\",\n","        \"SQL, Data Analysis, Big Data\",\n","        \"Project Management, Agile, Scrum\",\n","        \"React, JavaScript, HTML, CSS\",\n","        \"Python,OOP,Data Structures and Algorithms,Git,SQL\",\n","        \"Javascript,React,Node.js,MongoDB,REST API\",\n","        \"Node.js,Express.js,SQL,Microservices,Docker\",\n","        \"Pyhton,Machine Learning,SQL,TensorFlow,Data Visualization\"\n","    ],\n","    \"role\": [\n","        \"ML Engineer\",\n","        \"Data Analyst\",\n","        \"Product Manager\",\n","        \"Frontend Developer\",\n","        \"Software Engineer\",\n","        \"Full Stack Developer\",\n","        \"Backend Developer\",\n","        \"Data Scientist\"\n","    ]\n","}\n","\n","df = pd.DataFrame(data)\n","vectorizer = TfidfVectorizer()\n","X_vectors = vectorizer.fit_transform(df[\"resume\"])\n","model = LogisticRegression()\n","model.fit(X_vectors, df[\"role\"])\n","\n","# ğŸ”¹ Resume Scoring Function\n","def calculate_resume_score(skills):\n","    base_score = 0  # Start with a base score\n","    skill_boost = len(skills) * 5  # More skills â†’ Higher score\n","    role_weight = sum(10 for skill in skills if skill in [\"python\", \"sql\", \"machine learning\", \"aws\", \"docker\"])  # Critical industry skills\n","    score = min(base_score + skill_boost + role_weight, 100)  # Cap at 100\n","    return score\n","\n","# ğŸ”¹ Resume Analysis Function\n","def analyze_resume(pdf_path):\n","    resume_text = extract_text_from_pdf(pdf_path)\n","    if not resume_text:\n","        print(json.dumps({\"error\": \"Empty resume text extracted\"}))\n","        sys.exit(1)\n","\n","    skills = extract_skills(resume_text)\n","    suggested_roles = predict_roles(skills)\n","\n","    # ML Model Prediction\n","    resume_vector = vectorizer.transform([\" \".join(skills)]) if skills else vectorizer.transform([resume_text])\n","    predicted_role = model.predict(resume_vector)[0]\n","\n","    # Calculate Score\n","    resume_score = calculate_resume_score(skills)\n","\n","    # Improvement Suggestions\n","    improvements = []\n","    if \"python\" not in skills and \"java\" not in skills:\n","        improvements.append(\"Consider adding Python or Java programming skills.\")\n","    if \"sql\" not in skills and \"mongodb\" not in skills:\n","        improvements.append(\"Consider improving database knowledge (SQL, NoSQL).\")\n","    if \"cloud\" not in skills and \"aws\" not in skills and \"azure\" not in skills:\n","        improvements.append(\"Cloud expertise (AWS, Azure) is highly valued in modern tech.\")\n","    if \"data structures\" not in skills and \"algorithms\" not in skills:\n","        improvements.append(\"Strengthen knowledge of Data Structures and Algorithms for better problem-solving.\")\n","    if \"git\" not in skills:\n","        improvements.append(\"Include Git and version control experience to improve collaboration.\")\n","    if \"javascript\" in skills and \"typescript\" not in skills:\n","        improvements.append(\"Consider learning TypeScript for better scalability in frontend and backend development.\")\n","    if \"react\" in skills and \"redux\" not in skills:\n","        improvements.append(\"Learn Redux for better state management in React applications.\")\n","    if \"node\" in skills and \"express\" not in skills:\n","        improvements.append(\"Gain experience with Express.js for better backend development in Node.js.\")\n","    if \"sql\" in skills and \"mongodb\" not in skills:\n","        improvements.append(\"Consider learning MongoDB for NoSQL database expertise.\")\n","    if \"microservices\" not in skills:\n","        improvements.append(\"Gain knowledge of Microservices architecture for scalable backend systems.\")\n","    if \"python\" in skills and \"pandas\" not in skills:\n","        improvements.append(\"Learn Pandas for efficient data manipulation in Python.\")\n","    if \"machine learning\" in skills and \"statistics\" not in skills:\n","        improvements.append(\"Enhance understanding of Statistics for better ML model performance.\")\n","    if \"deep learning\" in skills and \"nlp\" not in skills and \"computer vision\" not in skills:\n","        improvements.append(\"Consider specializing in NLP or Computer Vision for advanced AI applications.\")\n","\n","    # âœ… Final Output\n","    result = {\n","        \"suggestedRoles\": list(set(suggested_roles + [predicted_role])),  # Combine ML + keyword roles\n","        \"resumeScore\": resume_score,\n","        \"improvements\": improvements\n","    }\n","    print(json.dumps(result))  # âœ… JSON output for API\n","\n","pdf_path = \"/content/resume2_SE_3.pdf\"\n","\n","# Run the resume analysis\n","analyze_resume(pdf_path)"],"metadata":{"id":"NTkkmUdZJnPI","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1748967017460,"user_tz":-330,"elapsed":2374,"user":{"displayName":"Pooja Divekar","userId":"05944496302832483529"}},"outputId":"614b98ba-145b-4173-f97f-b72f154426e6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"]},{"output_type":"stream","name":"stdout","text":["{\"suggestedRoles\": [\"Frontend Developer\", \"UX Designer\", \"DevOps Engineer\", \"Software Engineer\", \"Full Stack Developer\", \"Backend Developer\", \"Cloud Engineer\"], \"resumeScore\": 50, \"improvements\": [\"Consider improving database knowledge (SQL, NoSQL).\", \"Strengthen knowledge of Data Structures and Algorithms for better problem-solving.\", \"Include Git and version control experience to improve collaboration.\", \"Learn Redux for better state management in React applications.\", \"Gain knowledge of Microservices architecture for scalable backend systems.\"]}\n"]}]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","def match_resume_to_job(resume_text, jd_text):\n","    documents = [resume_text, jd_text]\n","    vectors = vectorizer.transform(documents)\n","    similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n","    return round(similarity * 100, 2)\n","\n","def rank_candidates(resume_paths, jd_text=None):\n","    results = []\n","    for path in resume_paths:\n","        resume_text = extract_text_from_pdf(path)\n","        skills = extract_skills(resume_text)\n","        score = calculate_resume_score(skills)\n","        match_score = match_resume_to_job(resume_text, jd_text) if jd_text else None\n","        results.append({\n","            \"file\": path,\n","            \"score\": score,\n","            \"match\": match_score\n","        })\n","    return sorted(results, key=lambda x: x[\"match\"] or x[\"score\"], reverse=True)"],"metadata":{"id":"YRJ_I_79Mvv4","executionInfo":{"status":"ok","timestamp":1748967017503,"user_tz":-330,"elapsed":7,"user":{"displayName":"Pooja Divekar","userId":"05944496302832483529"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import joblib\n","\n","joblib.dump(model, \"resume_model.joblib\")\n","joblib.dump(vectorizer, \"resume_vectorizer.joblib\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMJuj_1mms6r","executionInfo":{"status":"ok","timestamp":1748967876706,"user_tz":-330,"elapsed":80,"user":{"displayName":"Pooja Divekar","userId":"05944496302832483529"}},"outputId":"e188159c-e217-43ce-9ef4-b7274a8b762f"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['resume_vectorizer.joblib']"]},"metadata":{},"execution_count":7}]}]}